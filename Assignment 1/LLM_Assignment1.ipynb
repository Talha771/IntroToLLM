{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjtzTCY3ET4G"
      },
      "source": [
        "# CS 335: Introduction to Large Language Models\n",
        "## Assignment 01\n",
        "### **Total Marks**: 100\n",
        "### **Deadline**: Sunday, 3rd March, 2024, 11:59 PM\n",
        "### **Name**: Muhammad Talha\n",
        "### **ID**: mj06974"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_PuJY_809rM"
      },
      "source": [
        "#Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEsATiuR1Dm1"
      },
      "source": [
        "1. Please rename your notebook as *Assignment_1_aa1234.ipynb* before the final submission. Notebooks which do not follow appropriate naming convention will not be graded.\n",
        "\n",
        "2. Please submit your own work. If you have any questions, please feel free to reach out to the course instructors or RA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccbn_f1tuO5"
      },
      "source": [
        "# Assignment Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzVkeRPuFeE"
      },
      "source": [
        "In this assignment, you are required to fine tune a LLM model of your that classifies which human value category a textual arguement belongs to. Your model will evaluated against 1-baseline, random-baseline results on the following dataset: test, Nahjalbalagha, Zhihu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaTUH4roAbNK"
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUce6g7dikYE"
      },
      "outputs": [],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQpDqfqAeLf"
      },
      "source": [
        "# Download Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQHbYBWixhL"
      },
      "source": [
        "##Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNnoIZpRi4tG",
        "outputId": "67c2a793-ddd4-48d2-e9c2-e004f7a479ee"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/evaluator/evaluator.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1cuD7diLpQt"
      },
      "source": [
        "## 1-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qemjimf_F124",
        "outputId": "a0b95896-4da3-401b-a6d1-30d91a82b9a2"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/1-baseline/1-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpz1rfDxLsSd"
      },
      "source": [
        "## Random-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1T_HfBIL6cM",
        "outputId": "d1e699f9-0d23-4946-86ce-93d2f6235edb"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/random-baseline/random-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hP4MSUBLw6d"
      },
      "source": [
        "## Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbW6yi3-kzLV",
        "outputId": "3037cedb-d93a-454b-82dd-8b24e4ed5c50"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://zenodo.org/api/records/10564870/files-archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqWSKoZYg889",
        "outputId": "3a21c33b-e833-44d4-a287-399bbe0ed77e"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!unzip files-archive -d Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slE4sixQO3g3"
      },
      "outputs": [],
      "source": [
        "!mkdir Dataset/zhihu\n",
        "!mkdir Dataset/nahjalbalagha\n",
        "!mkdir Dataset/train\n",
        "!mkdir Dataset/test\n",
        "!mkdir Dataset/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6j3XShbOUcK",
        "outputId": "2e868218-3b04-476a-ff2c-8d461dc1f5ea"
      },
      "outputs": [],
      "source": [
        "!mv Dataset/*-zhihu.tsv Dataset/zhihu\n",
        "!mv Dataset/*-nahjalbalagha.tsv Dataset/nahjalbalagha\n",
        "!mv Dataset/*-training.tsv Dataset/train\n",
        "!mv Dataset/*-test.tsv Dataset/test\n",
        "!mv Dataset/*-validation.tsv Dataset/validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqfQxpk1rr3c"
      },
      "source": [
        "# Background Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VOGICHSEnPe"
      },
      "source": [
        "## Human Value Detection 2023 <br/>\n",
        "## SemEval 2023 Task 4. ValueEval: Identification of Human Values behind Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoK8u0VosGhF"
      },
      "source": [
        "\n",
        "\n",
        "Given a textual argument and a human value category, classify whether or not the argument draws on that category. This task uses a set of 20 value categories compiled from the social science literature and described in our [ACL paper](https://webis.de/publications.html#kiesel_2022b). Arguments are given as premise text, conclusion text, and binary stance of the premise to the conclusion (\"in favor of\" or \"against\").\n",
        "\n",
        "The 20 value categories are shown here on Schwartz' value continuum below:\n",
        "\n",
        "[![JEPBxUu.md.png](https://iili.io/JEPBxUu.md.png)](https://freeimage.host/i/JEPBxUu)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmfwBXIEqLN"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV37SsQqET4P"
      },
      "source": [
        "\n",
        "Data is provided as tab-separated values files with one header line. The arguments-validation.tsv files contain one argument per line: its unique argument ID, the conclusion, the premise's stance towards the conclusion, and the premise itself. Example with tab-separated columns are shown below\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Conclusion</span>\t<span class=\"column\">Stance</span>\t<span class=\"column\">Premise</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">We should prohibit school prayer</span>\t<span class=\"column\">against</span>\t<span class=\"column\">it should be allowed if the student wants to pray as long as it is not interfering with his classes</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">We should abolish the three-strikes laws</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">three strike laws can cause young people to be put away for life without a chance to straight out their life</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">The use of public defenders should be mandatory</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">the use of public defenders should be mandatory because some people don't have money for a lawyer and this would help those that don't</span>\n",
        "</pre>\n",
        "\n",
        "The labels-validation.tsv  files also contain one argument per line: its unique argument ID and one column for each of the 20 value categories with a 1 meaning that the argument resorts to the value category and a 0 that not. Example with tab-separated columns are shown below:\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Self-direction: thought</span>\t<span class=\"column\">Self-direction: action</span>\t<span class=\"column\">Stimulation</span>\t<span class=\"column\">Hedonism</span>\t<span class=\"column\">Achievement</span>\t<span class=\"column\">Power: dominance</span>\t<span class=\"column\">Power: resources</span>\t<span class=\"column\">Face</span>\t<span class=\"column\">Security: personal</span>\t<span class=\"column\">Security: societal</span>\t<span class=\"column\">Tradition</span>\t<span class=\"column\">Conformity: rules</span>\t<span class=\"column\">Conformity: interpersonal</span>\t<span class=\"column\">Humility</span>\t<span class=\"column\">Benevolence: caring</span>\t<span class=\"column\">Benevolence: dependability</span>\t<span class=\"column\">Universalism: concern</span>\t<span class=\"column\">Universalism: nature</span>\t<span class=\"column\">Universalism: tolerance</span>\t<span class=\"column\">Universalism: objectivity</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCUwSn5ET4R"
      },
      "source": [
        "In addition, there are other datasets for evaluating the robustness of our model: validation-zhihu from the recommendation and hotlist section of the Chinese question-answering website Zhihu, test-nahjalbalagha from and based on the Nahj al-Balagha.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTbj-CWGET4S"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0aIoUoET4T"
      },
      "source": [
        "Runs are evaluated on the basis of F1-score, Precision, and Recall: averaged over all value categories and for each category individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPq0nLudMRr6"
      },
      "source": [
        "## Baseline Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3bNgmUjmBm7"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!mkdir baseline\n",
        "!mkdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiNl_AFGMlKm"
      },
      "source": [
        "### 1-Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aAGZXIoxSk"
      },
      "source": [
        "#### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9M_yVXkCci",
        "outputId": "c2824bb1-896c-4b01-9fe1-4f1bb9d2dc34"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/test --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/test/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZimLuvQro0Un"
      },
      "source": [
        "#### Zhihu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdj9s6UapKNI",
        "outputId": "624c269f-0417-4cf7-8d2d-c6b73e0d5530"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/zhihu/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/zhihu/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM73FR4vo32i"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1fhW1vnpUe3",
        "outputId": "cc36d664-44f0-4965-d943-c62d77cc00e1"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/nahjalbalagha/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/nahjalbalagha/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCKuzb-RMp6u"
      },
      "source": [
        "### Random-Baseline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k07k6xKvpAPO"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-SbkcWxr0Sv",
        "outputId": "92d414d2-b2ac-4250-b21a-100f967fd910"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/test --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/test/ --inputRun baseline1 --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDhh7of4pCAS"
      },
      "source": [
        "#### Zhihu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN6mZ5jOr2Zp",
        "outputId": "4d95a320-54ef-4f04-9446-10983523ce37"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/zhihu/ --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/zhihu/ --inputRun baseline --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gg-ZIzQpEn3"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WurMCZZSsBIU",
        "outputId": "38e80f94-68d2-40f0-8b6a-f104306c1a01"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/nahjalbalagha/ --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/nahjalbalagha/ --inputRun baseline --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aub8gmh_xfOz"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvwbxxhcwIwo"
      },
      "source": [
        "## [20 Points] Task 01 - Load Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ6f0D1zwj9P"
      },
      "source": [
        "In this task, you are required to load the Training, Test, Validation, Nahjalbalagha & Zhihu into seperate dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification,BertModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import cuda\n",
        "import math\n",
        "import torch\n",
        "from transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\n",
        "from torch.utils.data import Dataset\n",
        "import evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hicJHRw0piGN"
      },
      "outputs": [],
      "source": [
        "# Importing files into dataframes:  naming convention: \n",
        "# dataset_arguments = the data\n",
        "# dataset_result_sem_eval = the answers to the data\n",
        "# dataset_result_level_1 = don't know what that is right now, maybe some answers for some other task. \n",
        "\n",
        "# Nahjalbalagah\n",
        "nahjalbalagha_arguments = pd.read_csv(\"Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "nahjalbalagha_result_sem_eval= pd.read_csv(\"Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "nahjalbalagha_result_level_1= pd.read_csv(\"Dataset/nahjalbalagha/level1-labels-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "# Zhihu \n",
        "zhihu_arguments = pd.read_csv(\"Dataset/zhihu/arguments-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "zhihu_result_sem_eval = pd.read_csv(\"Dataset/zhihu/labels-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "zhihu_result_level_1 = pd.read_csv(\"Dataset/zhihu/level1-labels-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Testing \n",
        "test_arguments = pd.read_csv(\"Dataset/test/arguments-test.tsv\",sep=\"\\t\")\n",
        "test_result_sem_eval = pd.read_csv(\"Dataset/test/labels-test.tsv\",sep=\"\\t\")\n",
        "test_result_level_1 = pd.read_csv(\"Dataset/test/level1-labels-test.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Training Dataset\n",
        "training_arguments = pd.read_csv(\"Dataset/train/arguments-training.tsv\",sep=\"\\t\")\n",
        "training_result_sem_eval = pd.read_csv(\"Dataset/train/labels-training.tsv\",sep=\"\\t\")\n",
        "training_result_level_1 = pd.read_csv(\"Dataset/train/level1-labels-training.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Validation \n",
        "validation_arguments = pd.read_csv(\"Dataset/validation/arguments-validation.tsv\",sep=\"\\t\")\n",
        "validation_result_sem_eval = pd.read_csv(\"Dataset/validation/labels-validation.tsv\",sep=\"\\t\")\n",
        "validation_result_level_1 = pd.read_csv(\"Dataset/validation/level1-labels-validation.tsv\",sep=\"\\t\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Defining Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [\n",
        "    \"Self-direction: thought\",\n",
        "    \"Self-direction: action\",\n",
        "    \"Stimulation\",\n",
        "    \"Hedonism\",\n",
        "    \"Achievement\",\n",
        "    \"Power: dominance\",\n",
        "    \"Power: resources\",\n",
        "    \"Face\",\n",
        "    \"Security: personal\",\n",
        "    \"Security: societal\",\n",
        "    \"Tradition\",\n",
        "    \"Conformity: rules\",\n",
        "    \"Conformity: interpersonal\",\n",
        "    \"Humility\",\n",
        "    \"Benevolence: caring\",\n",
        "    \"Benevolence: dependability\",\n",
        "    \"Universalism: concern\",\n",
        "    \"Universalism: nature\",\n",
        "    \"Universalism: tolerance\",\n",
        "    \"Universalism: objectivity\"\n",
        "]\n",
        "label_dict={\n",
        "    1: \"Self-direction: thought\",\n",
        "    2: \"Self-direction: action\",\n",
        "    3: \"Stimulation\",\n",
        "    4: \"Hedonism\",\n",
        "    5: \"Achievement\",\n",
        "    6: \"Power: dominance\",\n",
        "    7: \"Power: resources\",\n",
        "    8: \"Face\",\n",
        "    9: \"Security: personal\",\n",
        "    10: \"Security: societal\",\n",
        "    11: \"Tradition\",\n",
        "    12: \"Conformity: rules\",\n",
        "    13: \"Conformity: interpersonal\",\n",
        "    14: \"Humility\",\n",
        "    15: \"Benevolence: caring\",\n",
        "    16: \"Benevolence: dependability\",\n",
        "    17: \"Universalism: concern\",\n",
        "    18: \"Universalism: nature\",\n",
        "    19: \"Universalism: tolerance\",\n",
        "    20: \"Universalism: objectivity\"\n",
        "}\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Merging Dataframes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_argument_values= {}\n",
        "\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in training_result_sem_eval.iterrows():\n",
        "    # Get the 'Argument ID'\n",
        "    argument_id = row['Argument ID']\n",
        "    # Initialize an empty list to store column names with value 1\n",
        "    columns_with_1 = []\n",
        "    # Iterate over each column in the row (starting from index 1 to skip 'Argument ID')\n",
        "    for col in training_result_sem_eval.columns[1:]:\n",
        "        # Check if the value in the current column is 1\n",
        "        if row[col] == 1:\n",
        "            # If so, append the column name to the list\n",
        "            columns_with_1.append(label_dict_inverse[col])\n",
        "    # Add the 'Argument ID' and list of columns with value 1 to the dictionary\n",
        "    train_argument_values[argument_id] = columns_with_1\n",
        "df_argument_values = pd.DataFrame(train_argument_values.items(), columns=['Argument ID', 'label'])\n",
        "\n",
        "train_df = pd.merge(training_arguments, df_argument_values, on='Argument ID', how='left')\n",
        "\n",
        "train_labels=train_df['label'].tolist()\n",
        "\n",
        "train_labels = [max(label) if label and not any(math.isnan(x) for x in label) else 0 for label in train_labels]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10, 17, 17, 2, 20, 20, 14, 12, 9, 20, 20, 9, 17, 15, 10, 9, 19, 19, 17, 20, 5, 2, 9, 18, 19, 6, 17, 16, 14, 15, 10, 12, 20, 15, 16, 19, 15, 20, 17, 20, 16, 20, 17, 19, 15, 15, 20, 20, 19, 12, 20, 16, 20, 17, 19, 19, 12, 20, 15, 19, 15, 17, 17, 10, 15, 9, 17, 19, 14, 15, 17, 19, 16, 11, 15, 15, 9, 9, 3, 9, 17, 18, 15, 17, 19, 9, 17, 17, 17, 20, 13, 15, 7, 17, 7, 17, 9, 19, 17, 19, 18, 16, 19, 20, 9, 17, 20, 16, 19, 19, 15, 19, 20, 5, 17, 17, 17, 18, 20, 17, 9, 5, 20, 20, 15, 20, 20, 20, 5, 9, 16, 17, 15, 14, 17, 17, 12, 17, 16, 5, 19, 16, 16, 2, 17, 20, 20, 5, 16, 8, 10, 15, 20, 17, 15, 17, 19, 20, 11, 17, 15, 15, 19, 15, 19, 17, 17, 15, 18, 9, 18, 17, 16, 16, 9, 4, 18, 15, 15, 9, 17, 15, 19, 17, 15, 7, 5, 17, 9, 9, 17, 17, 9, 12, 15, 17, 15, 17, 15, 15, 19, 17, 9, 16, 12, 16, 20, 19, 17, 8, 17, 6, 20, 16, 16, 19, 19, 20, 19, 16, 17, 19, 2, 15, 12, 20, 17, 3, 17, 16, 20, 17, 17, 14, 17, 15, 1, 1, 20, 17, 20, 15, 17, 17, 20, 11, 12, 19, 17, 16, 12, 16, 17, 15, 17, 19, 17, 20, 20, 20, 19, 18, 19, 19, 14, 17, 19, 20, 19, 15, 15, 17, 5, 15, 13, 19, 20, 17, 17, 10, 16, 20, 20, 20, 2, 10, 16, 17, 14, 17, 17, 16, 17, 17, 16, 12, 15, 17, 18, 17, 10, 17, 14, 16, 20, 17, 17, 17, 20, 19, 17, 16, 20, 9, 20, 19, 17, 17, 16, 19, 15, 17, 20, 15, 17, 10, 17, 20, 10, 17, 15, 11, 20, 20, 17, 20, 20, 12, 20, 15, 17, 17, 17, 20, 20, 17, 19, 15, 19, 20, 15, 17, 10, 16, 19, 20, 15, 20, 17, 12, 17, 16, 18, 17, 12, 17, 19, 15, 16, 15, 18, 15, 17, 20, 20, 9, 17, 2, 16, 16, 20, 17, 18, 19, 19, 12, 19, 17, 17, 17, 17, 20, 16, 19, 17, 17, 15, 20, 16, 18, 19, 17, 17, 20, 16, 17, 15, 15, 20, 17, 20, 9, 12, 20, 15, 19, 20, 20, 17, 17, 18, 19, 17, 15, 9, 14, 17, 9, 12, 17, 18, 17, 17, 5, 9, 16, 18, 12, 12, 15, 17, 16, 15, 17, 15, 17, 18, 20, 17, 20, 12, 15, 14, 16, 16, 12, 17, 17, 17, 17, 15, 15, 12, 16, 18, 12, 17, 19, 17, 17, 12, 15, 17, 12, 15, 18, 17, 15, 2, 15, 17, 17, 17, 18, 2, 15, 17, 14, 20, 17, 20, 18, 19, 17, 16, 16, 17, 17, 7, 11, 20, 15, 12, 17, 15, 15, 17, 18, 20, 19, 19, 20, 16, 19, 19, 15, 11, 20, 20, 15, 17, 19, 9, 19, 11, 17, 17, 17, 9, 18, 20, 5, 18, 19, 20, 12, 12, 15, 17, 17, 20, 17, 15, 20, 17, 17, 19, 19, 17, 11, 17, 17, 17, 19, 17, 20, 16, 20, 17, 19, 12, 17, 20, 17, 17, 17, 16, 15, 16, 19, 15, 17, 9, 20, 18, 17, 17, 5, 19, 17, 18, 17, 19, 15, 15, 17, 19, 20, 20, 19, 10, 17, 12, 20, 17, 17, 16, 20, 17, 17, 17, 2, 14, 20, 20, 10, 19, 17, 20, 17, 17, 20, 15, 15, 13, 16, 19, 15, 11, 4, 15, 20, 17, 14, 9, 16, 19, 4, 17, 15, 17, 17, 12, 9, 16, 20, 16, 15, 17, 15, 17, 16, 20, 17, 5, 20, 17, 20, 9, 17, 17, 7, 17, 15, 17, 17, 15, 17, 16, 9, 20, 17, 17, 15, 20, 15, 14, 20, 17, 12, 14, 16, 15, 19, 20, 20, 16, 20, 16, 18, 19, 17, 12, 17, 12, 16, 20, 15, 15, 19, 16, 14, 19, 14, 20, 20, 14, 15, 17, 15, 17, 17, 17, 17, 17, 17, 15, 20, 19, 19, 19, 12, 20, 15, 20, 15, 17, 17, 9, 12, 10, 20, 17, 15, 16, 17, 15, 10, 15, 15, 20, 15, 17, 15, 12, 17, 17, 17, 20, 15, 12, 16, 17, 15, 9, 2, 16, 16, 19, 5, 12, 19, 16, 20, 5, 9, 17, 17, 15, 20, 17, 9, 17, 20, 12, 5, 15, 19, 20, 15, 2, 18, 17, 17, 20, 12, 15, 17, 14, 17, 20, 15, 9, 17, 9, 10, 14, 7, 17, 20, 5, 12, 11, 17, 15, 17, 15, 15, 16, 9, 9, 19, 10, 17, 17, 15, 15, 20, 10, 16, 17, 20, 15, 19, 10, 5, 17, 16, 19, 20, 15, 16, 15, 15, 16, 20, 17, 16, 15, 15, 9, 17, 9, 16, 17, 13, 20, 16, 17, 5, 17, 4, 9, 15, 15, 15, 17, 19, 16, 5, 17, 2, 20, 15, 16, 15, 19, 17, 20, 11, 17, 17, 12, 17, 15, 15, 17, 20, 5, 17, 17, 20, 19, 12, 15, 20, 20, 17, 15, 20, 16, 17, 8, 19, 20, 20, 15, 16, 17, 20, 18, 16, 20, 17, 15, 17, 20, 20, 17, 14, 2, 19, 16, 17, 20, 15, 20, 10, 17, 17, 17, 15, 17, 20, 15, 15, 17, 17, 5, 20, 17, 10, 15, 17, 20, 17, 15, 12, 2, 14, 11, 19, 17, 15, 19, 16, 19, 12, 20, 12, 9, 20, 10, 12, 19, 4, 19, 5, 15, 20, 19, 14, 15, 17, 17, 15, 14, 15, 14, 15, 7, 16, 20, 16, 17, 15, 19, 17, 17, 17, 17, 17, 15, 12, 12, 15, 17, 17, 12, 17, 15, 19, 17, 15, 2, 4, 20, 11, 2, 9, 17, 16, 12, 17, 15, 17, 9, 15, 12, 20, 15, 15, 9, 20, 19, 12, 15, 17, 17, 15, 14, 16, 17, 17, 17, 16, 20, 2, 7, 9, 15, 17, 17, 17, 12, 19, 2, 15, 15, 17, 16, 5, 6, 16, 12, 12, 14, 17, 9, 17, 17, 17, 20, 15, 20, 20, 15, 2, 15, 20, 17, 9, 17, 2, 20, 19, 2, 9, 19, 2, 20, 16, 17, 20, 20, 19, 18, 15, 17, 17, 17, 16, 11, 20, 17, 2, 17, 19, 8, 20, 13, 20, 17, 15, 14, 20, 17, 20, 9, 19, 20, 17, 12, 17, 16, 16, 16, 20, 8, 15, 15, 15, 5, 19, 2, 17, 19, 13, 17, 15, 19, 17, 12, 15, 9, 15, 17, 20, 15, 15, 17, 17, 17, 15, 20, 17, 17, 17, 17, 20, 20, 19, 15, 20, 16, 10, 15, 15, 20, 17, 17, 9, 15, 15, 17, 17, 17, 12, 15, 10, 17, 20, 18, 15, 16, 15, 17, 3, 16, 16, 15, 17, 17, 12, 5, 17, 12, 17, 15, 18, 17, 19, 17, 19, 12, 10, 12, 20, 17, 19, 16, 9, 17, 17, 9, 15, 15, 17, 17, 19, 20, 19, 15, 4, 15, 10, 20, 20, 16, 16, 12, 19, 17, 10, 15, 15, 16, 11, 9, 17, 20, 17, 17, 20, 17, 17, 15, 20, 19, 12, 12, 5, 20, 19, 12, 15, 20, 17, 15, 15, 9, 17, 19, 17, 13, 9, 17, 20, 17, 17, 15, 17, 17, 20, 20, 17, 9, 17, 12, 5, 13, 17, 17, 19, 18, 5, 15, 20, 15, 20, 17, 15, 12, 15, 17, 16, 15, 5, 9, 9, 5, 12, 9, 20, 10, 4, 17, 4, 5, 10, 5, 5, 17, 15, 17, 17, 17, 15, 20, 15, 17, 17, 16, 12, 17, 9, 19, 19, 17, 17, 19, 19, 15, 11, 17, 20, 15, 12, 17, 15, 2, 5, 17, 1, 20, 20, 17, 19, 20, 9, 15, 17, 17, 15, 16, 15, 17, 15, 16, 20, 20, 15, 17, 17, 17, 10, 12, 9, 20, 17, 20, 14, 16, 20, 15, 9, 19, 17, 20, 17, 10, 17, 2, 17, 9, 17, 20, 17, 17, 17, 20, 17, 20, 15, 16, 20, 20, 9, 15, 17, 10, 17, 20, 17, 9, 10, 15, 20, 17, 1, 17, 20, 20, 17, 12, 9, 17, 15, 16, 20, 10, 17, 17, 17, 17, 17, 17, 17, 16, 9, 9, 5, 17, 17, 16, 16, 9, 17, 17, 12, 17, 9, 19, 10, 12, 9, 17, 15, 17, 15, 17, 15, 15, 9, 20, 20, 5, 15, 20, 20, 15, 9, 18, 5, 16, 18, 17, 20, 10, 17, 16, 9, 9, 16, 19, 17, 20, 15, 17, 15, 15, 20, 20, 9, 17, 19, 20, 20, 20, 20, 11, 15, 17, 15, 15, 17, 17, 10, 20, 17, 11, 20, 11, 5, 9, 20, 17, 2, 9, 9, 10, 12, 15, 17, 9, 17, 15, 17, 17, 20, 5, 17, 20, 20, 20, 20, 17, 9, 17, 17, 17, 9, 20, 20, 9, 20, 17, 15, 20, 5, 17, 17, 9, 16, 9, 15, 20, 20, 9, 20, 15, 17, 17, 20, 20, 5, 18, 18, 9, 20, 20, 20, 15, 18, 17, 5, 16, 20, 20, 8, 17, 20, 18, 20, 9, 9, 20, 20, 17, 20, 17, 10, 20, 10, 17, 20, 19, 19, 17, 20, 20, 20, 17, 20, 20, 20, 19, 17, 17, 19, 17, 5, 20, 17, 15, 20, 17, 14, 19, 17, 20, 20, 11, 20, 20, 20, 9, 14, 18, 17, 20, 17, 19, 5, 16, 5, 20, 17, 19, 12, 20, 10, 12, 9, 9, 9, 12, 2, 15, 14, 11, 17, 15, 20, 20, 20, 18, 20, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 18, 18, 17, 20, 18, 18, 7, 18, 18, 18, 20, 18, 18, 18, 20, 20, 18, 18, 19, 18, 18, 20, 17, 17, 20, 20, 20, 20, 20, 18, 18, 20, 20, 18, 9, 18, 20, 20, 18, 18, 18, 20, 18, 20, 12, 18, 18, 17, 7, 17, 20, 19, 19, 17, 18, 17, 20, 20, 17, 20, 20, 17, 17, 17, 19, 19, 16, 11, 17, 17, 16, 20, 17, 19, 10, 9, 15, 15, 14, 11, 19, 5, 20, 18, 11, 19, 20, 18, 18, 17, 15, 2, 18, 20, 20, 18, 17, 10, 20, 20, 20, 20, 20, 16, 19, 17, 18, 20, 18, 20, 20, 15, 17, 20, 20, 18, 19, 20, 20, 18, 20, 18, 20, 18, 19, 18, 20, 19, 17, 19, 20, 20, 18, 18, 19, 20, 12, 20, 17, 17, 19, 10, 17, 12, 20, 10, 20, 20, 17, 11, 17, 20, 10, 16, 15, 17, 20, 15, 19, 17, 16, 17, 20, 20, 8, 16, 15, 10, 5, 15, 20, 20, 19, 9, 20, 19, 16, 17, 18, 18, 20, 17, 20, 20, 18, 20, 20, 19, 18, 20, 9, 19, 11, 20, 17, 15, 19, 19, 19, 17, 2, 2, 10, 19, 17, 20, 6, 20, 20, 15, 15, 20, 9, 17, 20, 16, 17, 17, 20, 12, 15, 10, 19, 17, 19, 10, 20, 16, 20, 17, 20, 20, 16, 17, 15, 17, 17, 18, 12, 20, 17, 17, 17, 17, 10, 14, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 19, 20, 20, 20, 20, 17]\n"
          ]
        }
      ],
      "source": [
        "validate_argument_values= {}\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in validation_result_sem_eval.iterrows():\n",
        "    # Get the 'Argument ID'\n",
        "    argument_id = row['Argument ID']\n",
        "    # Initialize an empty list to store column names with value 1\n",
        "    columns_with_1 = []\n",
        "    # Iterate over each column in the row (starting from index 1 to skip 'Argument ID')\n",
        "    for col in validation_result_sem_eval.columns[1:]:\n",
        "        # Check if the value in the current column is 1\n",
        "        if row[col] == 1:\n",
        "            # If so, append the column name to the list\n",
        "            columns_with_1.append(label_dict_inverse[col])\n",
        "\n",
        "    # Add the 'Argument ID' and list of columns with value 1 to the dictionary\n",
        "    validate_argument_values[argument_id] = columns_with_1\n",
        "df_argument_values = pd.DataFrame(validate_argument_values.items(), columns=['Argument ID', 'label'])\n",
        "\n",
        "validate_df = pd.merge(validation_arguments, df_argument_values, on='Argument ID', how='left')\n",
        "validate_labels=validate_df['label'].tolist()\n",
        "\n",
        "validate_labels = [max(label) if label and not any(math.isnan(x) for x in label) else 0 for label in validate_labels]\n",
        "print(validate_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [10 Points] Task 02 - Define Tokenizer & Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-GrMJPcx3W3"
      },
      "source": [
        "In this task, you are required to define the Tokenizer and LLM model of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "iNVCZzye2Mz4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Write your code here\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',num_labels=20)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",id2label=label_dict,label2id=label_dict_inverse)\n",
        "model.to(device)\n",
        "\n",
        "train_data = train_df.apply(lambda row: ','.join(map(str, row)), axis=1).tolist()\n",
        "validate_data=validate_df.apply(lambda row: ','.join(map(str, row)), axis=1).tolist()\n",
        "\n",
        "\n",
        "train_encodings=tokenizer(train_data,padding='max_length',truncation=True)\n",
        "validate_encodings=tokenizer(validate_data,padding='max_length',truncation=True)\n",
        "\n",
        "# for sentence in train_data:\n",
        "#     train_encodings.append(tokenize(sentence))\n",
        "# validate_encodings=[]\n",
        "# for sentence in validate_data:\n",
        "#     validate_encodings.append(tokenizer(sentence))\n",
        "# print(train_encodings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataLoader(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset class for handling tokenized text data and corresponding labels.\n",
        "    Inherits from torch.utils.data.Dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, encodings,labels):\n",
        "        \"\"\"\n",
        "        Initializes the DataLoader class with encodings and labels.\n",
        "\n",
        "        Args:\n",
        "            encodings (dict): A dictionary containing tokenized input text data\n",
        "                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n",
        "            labels (list): A list of integer labels for the input text data.\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the data item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            item (dict): A dictionary containing the tokenized data and the corresponding label.\n",
        "        \"\"\"\n",
        "        # Retrieve tokenized data for the given index\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # Add the label for the given index to the item dictionary\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of data items in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            (int): The number of data items in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.labels)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "train_dataloader=DataLoader(train_encodings,train_labels)\n",
        "\n",
        "validate_dataloader=DataLoader(validate_encodings,validate_labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHVo6_LBBmS"
      },
      "source": [
        "## [20 Points] Task 03 - Optimizer & Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_U-toJPyWU2"
      },
      "source": [
        "In this task, you are required to define the hyperparameters & the optimizer for training your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "IRCnPVc1y8C-"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "BATCH_SIZE = 32\n",
        "NUM_PROCS = 32\n",
        "LR = 0.00005\n",
        "EPOCHS = 5\n",
        "MODEL = 'bert-base-uncased'\n",
        "OUT_DIR = 'finetuned '+ MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0hSUmrBBGI4"
      },
      "source": [
        "## [20 Points] Task 04 -  Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIT5b7E6yuC3"
      },
      "source": [
        "In this task, you are required to implement the training loop for fine tuning your model. You are also required to plot on the same graph: Loss vs Epochs & Accuracy vs Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_623690/4072662420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 if (\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2943\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2944\u001b[0m                     \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m                     \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
          ]
        }
      ],
      "source": [
        "#Write your code\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "trainer=Trainer(\n",
        "    model=model, \n",
        "    train_dataset=train_dataloader,         \n",
        "    eval_dataset=validate_dataloader,  \n",
        "    args=TrainingArguments('test-trainer'),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NOEm2ezYUt"
      },
      "source": [
        "## [10 Points]  Task 05 - Model Evaluation: Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kjnR9qzuZG"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Test dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkJAygxszgj7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_588789/3969361791.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrainingArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test-trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 if (\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2943\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2944\u001b[0m                     \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m                     \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU4HaMYnzhJv"
      },
      "source": [
        "## [10 Points]  Task 06 - Model Evaluation: Zhihu Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT5t6TbG0F_O"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Zhihu\n",
        " dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVP0kNHOzixT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4ZsjvNzj0-"
      },
      "source": [
        "## [10 Points]  Task 07 - Model Evaluation: Nahjalbalagha Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KkhxR3p0KAF"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Nahjalbalagha dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQnoTEUzlJU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I0v4IKS0OA9"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6B-tga80RDu"
      },
      "source": [
        "In this section, cite any resources or references that you use for solving this assignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "title = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding}\n",
        "Link : https://huggingface.co/google-bert/bert-base-uncased \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
