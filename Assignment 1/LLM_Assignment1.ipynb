{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjtzTCY3ET4G"
      },
      "source": [
        "# CS 335: Introduction to Large Language Models\n",
        "## Assignment 01\n",
        "### **Total Marks**: 100\n",
        "### **Deadline**: Sunday, 3rd March, 2024, 11:59 PM\n",
        "### **Name**: Muhammad Talha\n",
        "### **ID**: mj06974"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_PuJY_809rM"
      },
      "source": [
        "#Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEsATiuR1Dm1"
      },
      "source": [
        "1. Please rename your notebook as *Assignment_1_aa1234.ipynb* before the final submission. Notebooks which do not follow appropriate naming convention will not be graded.\n",
        "\n",
        "2. Please submit your own work. If you have any questions, please feel free to reach out to the course instructors or RA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccbn_f1tuO5"
      },
      "source": [
        "# Assignment Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzVkeRPuFeE"
      },
      "source": [
        "In this assignment, you are required to fine tune a LLM model of your that classifies which human value category a textual arguement belongs to. Your model will evaluated against 1-baseline, random-baseline results on the following dataset: test, Nahjalbalagha, Zhihu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaTUH4roAbNK"
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUce6g7dikYE"
      },
      "outputs": [],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQpDqfqAeLf"
      },
      "source": [
        "# Download Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQHbYBWixhL"
      },
      "source": [
        "##Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNnoIZpRi4tG",
        "outputId": "67c2a793-ddd4-48d2-e9c2-e004f7a479ee"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/evaluator/evaluator.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1cuD7diLpQt"
      },
      "source": [
        "## 1-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qemjimf_F124",
        "outputId": "a0b95896-4da3-401b-a6d1-30d91a82b9a2"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/1-baseline/1-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpz1rfDxLsSd"
      },
      "source": [
        "## Random-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1T_HfBIL6cM",
        "outputId": "d1e699f9-0d23-4946-86ce-93d2f6235edb"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/random-baseline/random-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hP4MSUBLw6d"
      },
      "source": [
        "## Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbW6yi3-kzLV",
        "outputId": "3037cedb-d93a-454b-82dd-8b24e4ed5c50"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://zenodo.org/api/records/10564870/files-archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqWSKoZYg889",
        "outputId": "3a21c33b-e833-44d4-a287-399bbe0ed77e"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!unzip files-archive -d Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slE4sixQO3g3"
      },
      "outputs": [],
      "source": [
        "!mkdir Dataset/zhihu\n",
        "!mkdir Dataset/nahjalbalagha\n",
        "!mkdir Dataset/train\n",
        "!mkdir Dataset/test\n",
        "!mkdir Dataset/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6j3XShbOUcK",
        "outputId": "2e868218-3b04-476a-ff2c-8d461dc1f5ea"
      },
      "outputs": [],
      "source": [
        "!mv Dataset/*-zhihu.tsv Dataset/zhihu\n",
        "!mv Dataset/*-nahjalbalagha.tsv Dataset/nahjalbalagha\n",
        "!mv Dataset/*-training.tsv Dataset/train\n",
        "!mv Dataset/*-test.tsv Dataset/test\n",
        "!mv Dataset/*-validation.tsv Dataset/validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqfQxpk1rr3c"
      },
      "source": [
        "# Background Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VOGICHSEnPe"
      },
      "source": [
        "## Human Value Detection 2023 <br/>\n",
        "## SemEval 2023 Task 4. ValueEval: Identification of Human Values behind Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoK8u0VosGhF"
      },
      "source": [
        "\n",
        "\n",
        "Given a textual argument and a human value category, classify whether or not the argument draws on that category. This task uses a set of 20 value categories compiled from the social science literature and described in our [ACL paper](https://webis.de/publications.html#kiesel_2022b). Arguments are given as premise text, conclusion text, and binary stance of the premise to the conclusion (\"in favor of\" or \"against\").\n",
        "\n",
        "The 20 value categories are shown here on Schwartz' value continuum below:\n",
        "\n",
        "[![JEPBxUu.md.png](https://iili.io/JEPBxUu.md.png)](https://freeimage.host/i/JEPBxUu)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmfwBXIEqLN"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV37SsQqET4P"
      },
      "source": [
        "\n",
        "Data is provided as tab-separated values files with one header line. The arguments-validation.tsv files contain one argument per line: its unique argument ID, the conclusion, the premise's stance towards the conclusion, and the premise itself. Example with tab-separated columns are shown below\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Conclusion</span>\t<span class=\"column\">Stance</span>\t<span class=\"column\">Premise</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">We should prohibit school prayer</span>\t<span class=\"column\">against</span>\t<span class=\"column\">it should be allowed if the student wants to pray as long as it is not interfering with his classes</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">We should abolish the three-strikes laws</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">three strike laws can cause young people to be put away for life without a chance to straight out their life</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">The use of public defenders should be mandatory</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">the use of public defenders should be mandatory because some people don't have money for a lawyer and this would help those that don't</span>\n",
        "</pre>\n",
        "\n",
        "The labels-validation.tsv  files also contain one argument per line: its unique argument ID and one column for each of the 20 value categories with a 1 meaning that the argument resorts to the value category and a 0 that not. Example with tab-separated columns are shown below:\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Self-direction: thought</span>\t<span class=\"column\">Self-direction: action</span>\t<span class=\"column\">Stimulation</span>\t<span class=\"column\">Hedonism</span>\t<span class=\"column\">Achievement</span>\t<span class=\"column\">Power: dominance</span>\t<span class=\"column\">Power: resources</span>\t<span class=\"column\">Face</span>\t<span class=\"column\">Security: personal</span>\t<span class=\"column\">Security: societal</span>\t<span class=\"column\">Tradition</span>\t<span class=\"column\">Conformity: rules</span>\t<span class=\"column\">Conformity: interpersonal</span>\t<span class=\"column\">Humility</span>\t<span class=\"column\">Benevolence: caring</span>\t<span class=\"column\">Benevolence: dependability</span>\t<span class=\"column\">Universalism: concern</span>\t<span class=\"column\">Universalism: nature</span>\t<span class=\"column\">Universalism: tolerance</span>\t<span class=\"column\">Universalism: objectivity</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCUwSn5ET4R"
      },
      "source": [
        "In addition, there are other datasets for evaluating the robustness of our model: validation-zhihu from the recommendation and hotlist section of the Chinese question-answering website Zhihu, test-nahjalbalagha from and based on the Nahj al-Balagha.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTbj-CWGET4S"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0aIoUoET4T"
      },
      "source": [
        "Runs are evaluated on the basis of F1-score, Precision, and Recall: averaged over all value categories and for each category individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPq0nLudMRr6"
      },
      "source": [
        "## Baseline Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3bNgmUjmBm7"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!mkdir baseline\n",
        "!mkdir output\n",
        "!pip install -U accelerate\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiNl_AFGMlKm"
      },
      "source": [
        "### 1-Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aAGZXIoxSk"
      },
      "source": [
        "#### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9M_yVXkCci",
        "outputId": "c2824bb1-896c-4b01-9fe1-4f1bb9d2dc34"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/test --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/test/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZimLuvQro0Un"
      },
      "source": [
        "#### Zhihu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdj9s6UapKNI",
        "outputId": "624c269f-0417-4cf7-8d2d-c6b73e0d5530"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/zhihu/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/zhihu/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM73FR4vo32i"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1fhW1vnpUe3",
        "outputId": "cc36d664-44f0-4965-d943-c62d77cc00e1"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/nahjalbalagha/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/nahjalbalagha/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCKuzb-RMp6u"
      },
      "source": [
        "### Random-Baseline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k07k6xKvpAPO"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-SbkcWxr0Sv",
        "outputId": "92d414d2-b2ac-4250-b21a-100f967fd910"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/test --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/test/ --inputRun baseline1 --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDhh7of4pCAS"
      },
      "source": [
        "#### Zhihu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN6mZ5jOr2Zp",
        "outputId": "4d95a320-54ef-4f04-9446-10983523ce37"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/zhihu/ --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/zhihu/ --inputRun baseline --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gg-ZIzQpEn3"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WurMCZZSsBIU",
        "outputId": "38e80f94-68d2-40f0-8b6a-f104306c1a01"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/nahjalbalagha/ --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/nahjalbalagha/ --inputRun baseline --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aub8gmh_xfOz"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvwbxxhcwIwo"
      },
      "source": [
        "## [20 Points] Task 01 - Load Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ6f0D1zwj9P"
      },
      "source": [
        "In this task, you are required to load the Training, Test, Validation, Nahjalbalagha & Zhihu into seperate dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification,BertModel,DistilBertForSequenceClassification,DistilBertTokenizerFast\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import cuda\n",
        "import math\n",
        "from transformers import pipeline, BertForSequenceClassification\n",
        "import evaluate\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hicJHRw0piGN"
      },
      "outputs": [],
      "source": [
        "# Importing files into dataframes:  naming convention: \n",
        "# dataset_arguments = the data\n",
        "# dataset_result_sem_eval = the answers to the data\n",
        "# dataset_result_level_1 = don't know what that is right now, maybe some answers for some other task. \n",
        "\n",
        "# Nahjalbalagah\n",
        "nahjalbalagha_arguments = pd.read_csv(\"Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\",sep=\"\\`t\")\n",
        "nahjalbalagha_result_sem_eval= pd.read_csv(\"Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "nahjalbalagha_result_level_1= pd.read_csv(\"Dataset/nahjalbalagha/level1-labels-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "# Zhihu \n",
        "zhihu_arguments = pd.read_csv(\"Dataset/zhihu/arguments-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "zhihu_result_sem_eval = pd.read_csv(\"Dataset/zhihu/labels-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "zhihu_result_level_1 = pd.read_csv(\"Dataset/zhihu/level1-labels-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Testing \n",
        "test_arguments = pd.read_csv(\"Dataset/test/arguments-test.tsv\",sep=\"\\t\")\n",
        "test_result_sem_eval = pd.read_csv(\"Dataset/test/labels-test.tsv\",sep=\"\\t\")\n",
        "test_result_level_1 = pd.read_csv(\"Dataset/test/level1-labels-test.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Training Dataset\n",
        "training_arguments = pd.read_csv(\"Dataset/train/arguments-training.tsv\",sep=\"\\t\")\n",
        "training_result_sem_eval = pd.read_csv(\"Dataset/train/labels-training.tsv\",sep=\"\\t\")\n",
        "training_result_level_1 = pd.read_csv(\"Dataset/train/level1-labels-training.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Validation \n",
        "validation_arguments = pd.read_csv(\"Dataset/validation/arguments-validation.tsv\",sep=\"\\t\")\n",
        "validation_result_sem_eval = pd.read_csv(\"Dataset/validation/labels-validation.tsv\",sep=\"\\t\")\n",
        "validation_result_level_1 = pd.read_csv(\"Dataset/validation/level1-labels-validation.tsv\",sep=\"\\t\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Defining Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [\n",
        "    \"Self-direction: thought\",\n",
        "    \"Self-direction: action\",\n",
        "    \"Stimulation\",\n",
        "    \"Hedonism\",\n",
        "    \"Achievement\",\n",
        "    \"Power: dominance\",\n",
        "    \"Power: resources\",\n",
        "    \"Face\",\n",
        "    \"Security: personal\",\n",
        "    \"Security: societal\",\n",
        "    \"Tradition\",\n",
        "    \"Conformity: rules\",\n",
        "    \"Conformity: interpersonal\",\n",
        "    \"Humility\",\n",
        "    \"Benevolence: caring\",\n",
        "    \"Benevolence: dependability\",\n",
        "    \"Universalism: concern\",\n",
        "    \"Universalism: nature\",\n",
        "    \"Universalism: tolerance\",\n",
        "    \"Universalism: objectivity\"\n",
        "]\n",
        "label_dict={\n",
        "    0: \"Self-direction: thought\",\n",
        "    1: \"Self-direction: action\",\n",
        "    2: \"Stimulation\",\n",
        "    3: \"Hedonism\",\n",
        "    4: \"Achievement\",\n",
        "    5: \"Power: dominance\",\n",
        "    6: \"Power: resources\",\n",
        "    7: \"Face\",\n",
        "    8: \"Security: personal\",\n",
        "    9: \"Security: societal\",\n",
        "    10: \"Tradition\",\n",
        "    11: \"Conformity: rules\",\n",
        "    12: \"Conformity: interpersonal\",\n",
        "    13: \"Humility\",\n",
        "    14: \"Benevolence: caring\",\n",
        "    15: \"Benevolence: dependability\",\n",
        "    16: \"Universalism: concern\",\n",
        "    17: \"Universalism: nature\",\n",
        "    18: \"Universalism: tolerance\",\n",
        "    19: \"Universalism: objectivity\"\n",
        "}\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Merging Dataframes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_argument_values= {}\n",
        "\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in training_result_sem_eval.iterrows():\n",
        "    # Get the 'Argument ID'\n",
        "    argument_id = row['Argument ID']\n",
        "    # Initialize an empty list to store column names with value 1\n",
        "    columns_with_1 = []\n",
        "    # Iterate over each column in the row (starting from index 1 to skip 'Argument ID')\n",
        "    for col in training_result_sem_eval.columns[1:]:\n",
        "        # Check if the value in the current column is 1\n",
        "        if row[col] == 1:\n",
        "            # If so, append the column name to the list\n",
        "            columns_with_1.append(label_dict_inverse[col])\n",
        "    # Add the 'Argument ID' and list of columns with value 1 to the dictionary\n",
        "    train_argument_values[argument_id] = columns_with_1\n",
        "df_argument_values = pd.DataFrame(train_argument_values.items(), columns=['Argument ID', 'label'])\n",
        "\n",
        "train_df = pd.merge(training_arguments, df_argument_values, on='Argument ID', how='left')\n",
        "\n",
        "train_labels=train_df['label'].tolist()\n",
        "\n",
        "train_labels = [max(label) if label and not any(math.isnan(x) for x in label) else 0 for label in train_labels]\n",
        "# print(max(train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validate_argument_values= {}\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in validation_result_sem_eval.iterrows():\n",
        "    # Get the 'Argument ID'\n",
        "    argument_id = row['Argument ID']\n",
        "    # Initialize an empty list to store column names with value 1\n",
        "    columns_with_1 = []\n",
        "    # Iterate over each column in the row (starting from index 1 to skip 'Argument ID')\n",
        "    for col in validation_result_sem_eval.columns[1:]:\n",
        "        # Check if the value in the current column is 1\n",
        "        if row[col] == 1:\n",
        "            # If so, append the column name to the list\n",
        "            columns_with_1.append(label_dict_inverse[col])\n",
        "\n",
        "    # Add the 'Argument ID' and list of columns with value 1 to the dictionary\n",
        "    validate_argument_values[argument_id] = columns_with_1\n",
        "df_argument_values = pd.DataFrame(validate_argument_values.items(), columns=['Argument ID', 'label'])\n",
        "\n",
        "validate_df = pd.merge(validation_arguments, df_argument_values, on='Argument ID', how='left')\n",
        "validate_labels=validate_df['label'].tolist()\n",
        "\n",
        "validate_labels = [max(label) if label and not any(math.isnan(x) for x in label) else 0 for label in validate_labels]\n",
        "\n",
        "# print(max(validate_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [10 Points] Task 02 - Define Tokenizer & Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-GrMJPcx3W3"
      },
      "source": [
        "In this task, you are required to define the Tokenizer and LLM model of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNVCZzye2Mz4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Write your code here\n",
        "\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "# model.to('cpu')\n",
        "\n",
        "# train=train_df['Conclusion'].tolist()\n",
        "# validate=validate_df['Conclusion'].tolist()\n",
        "# train_encoding=tokenizer(train,padding=True,truncation=True)\n",
        "# validate_encoding=tokenizer(validate,padding=True,truncation=True)\n",
        "\n",
        "\n",
        "# # tokenized_train = [tokenizer.tokenize(sentence) for sentence in train]\n",
        "# # train_labels=torch.tensor(train_labels)\n",
        "# # train_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_train]\n",
        "# # train_input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(ids) for ids in train_input_ids], batch_first=True)\n",
        "# # train_attention_masks = torch.tensor([[1] * len(ids) for ids in train_input_ids])  # Assuming all tokens are valid\n",
        "# # train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "\n",
        "# # tokenized_validate = [tokenizer.tokenize(sentence) for sentence in validate]\n",
        "# # validate_labels=torch.tensor(validate_labels)\n",
        "# # validate_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_validate]\n",
        "# # validate_input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(ids) for ids in validate_input_ids], batch_first=True)\n",
        "# # validate_attention_masks = torch.tensor([[1] * len(ids) for ids in validate_input_ids])  # Assuming all tokens are valid\n",
        "# # validate_dataset = TensorDataset(validate_input_ids, validate_attention_masks, validate_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Write your code here\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=20)  # Assuming 20 human value categories\n",
        "model.to('cuda')\n",
        "\n",
        "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "\n",
        "train=train_df['Premise'].tolist()\n",
        "validate=validate_df['Premise'].tolist()\n",
        "train_encodings = tokenizer(train, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "validate_encodings=tokenizer(validate,truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "# tokenized_train = [tokenizer.tokenize(sentence) for sentence in train]\n",
        "# train_labels=torch.tensor(train_labels)\n",
        "# train_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_train]\n",
        "# train_input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(ids) for ids in train_input_ids], batch_first=True)\n",
        "# train_attention_masks = torch.tensor([[1] * len(ids) for ids in train_input_ids])  # Assuming all tokens are valid\n",
        "# train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "\n",
        "# tokenized_validate = [tokenizer.tokenize(sentence) for sentence in validate]\n",
        "# validate_labels=torch.tensor(validate_labels)\n",
        "# validate_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_validate]\n",
        "# validate_input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(ids) for ids in validate_input_ids], batch_first=True)\n",
        "# validate_attention_masks = torch.tensor([[1] * len(ids) for ids in validate_input_ids])  # Assuming all tokens are valid\n",
        "# validate_dataset = TensorDataset(validate_input_ids, validate_attention_masks, validate_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "train_dataset=CustomDataset(train_encodings,train_labels)\n",
        "validate_dataset=CustomDataset(validate_encodings,validate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHVo6_LBBmS"
      },
      "source": [
        "## [20 Points] Task 03 - Optimizer & Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_U-toJPyWU2"
      },
      "source": [
        "In this task, you are required to define the hyperparameters & the optimizer for training your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0hSUmrBBGI4"
      },
      "source": [
        "## [20 Points] Task 04 -  Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIT5b7E6yuC3"
      },
      "source": [
        "In this task, you are required to implement the training loop for fine tuning your model. You are also required to plot on the same graph: Loss vs Epochs & Accuracy vs Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Write your code\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=2,  # batch size per device during training\n",
        "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,  # The instantiated Transformers model to be trained\n",
        "    args=training_args,  # Training arguments\n",
        "    train_dataset=train_dataset,  # Training dataset\n",
        "    eval_dataset=train_dataset, \n",
        "    # Evaluation dataset\n",
        "    )\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.evaluate()\n",
        "save_dir='./finetined'\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetuned_model=BertForSequenceClassification.from_pretrained(save_dir)  # Assuming 20 human value categories\n",
        "finetuned_tokenizer=BertTokenizer.from_pretrained(save_dir)\n",
        "nlp= pipeline(\"sentiment-analysis\", model=finetuned_model, tokenizer=finetuned_tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NOEm2ezYUt"
      },
      "source": [
        "## [10 Points]  Task 05 - Model Evaluation: Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kjnR9qzuZG"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Test dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "AkJAygxszgj7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Argument ID                                              A26004\n",
            "Conclusion                     We should end affirmative action\n",
            "Stance                                                  against\n",
            "Premise        affirmative action helps with employment equity.\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "test_premise=test_arguments['Premise'].tolist()\n",
        "test_premise_ids=test_arguments[\"Argument ID\"].tolist()\n",
        "\n",
        "test_answer=[]\n",
        "columns = [\n",
        "    \"Argument ID\",\n",
        "    \"Self-direction: thought\",\n",
        "    \"Self-direction: action\",\n",
        "    \"Stimulation\",\n",
        "    \"Hedonism\",\n",
        "    \"Achievement\",\n",
        "    \"Power: dominance\",\n",
        "    \"Power: resources\",\n",
        "    \"Face\",\n",
        "    \"Security: personal\",\n",
        "    \"Security: societal\",\n",
        "    \"Tradition\",\n",
        "    \"Conformity: rules\",\n",
        "    \"Conformity: interpersonal\",\n",
        "    \"Humility\",\n",
        "    \"Benevolence: caring\",\n",
        "    \"Benevolence: dependability\",\n",
        "    \"Universalism: concern\",\n",
        "    \"Universalism: nature\",\n",
        "    \"Universalism: tolerance\",\n",
        "    \"Universalism: objectivity\"\n",
        "]\n",
        "\n",
        "data_frame=df = pd.DataFrame(columns=columns)\n",
        "data_frame[\"Argument ID\"]=test_premise_ids\n",
        "for index,row in test_arguments.iterrows():\n",
        "    print(row['Premise'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU4HaMYnzhJv"
      },
      "source": [
        "## [10 Points]  Task 06 - Model Evaluation: Zhihu Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT5t6TbG0F_O"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Zhihu\n",
        " dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVP0kNHOzixT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4ZsjvNzj0-"
      },
      "source": [
        "## [10 Points]  Task 07 - Model Evaluation: Nahjalbalagha Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KkhxR3p0KAF"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Nahjalbalagha dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQnoTEUzlJU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I0v4IKS0OA9"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6B-tga80RDu"
      },
      "source": [
        "In this section, cite any resources or references that you use for solving this assignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "title = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding}\n",
        "Link : https://huggingface.co/google-bert/bert-base-uncased \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
