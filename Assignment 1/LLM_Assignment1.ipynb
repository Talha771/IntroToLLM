{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjtzTCY3ET4G"
      },
      "source": [
        "# CS 335: Introduction to Large Language Models\n",
        "## Assignment 01\n",
        "### **Total Marks**: 100\n",
        "### **Deadline**: Sunday, 3rd March, 2024, 11:59 PM\n",
        "### **Name**: Muhammad Talha\n",
        "### **ID**: mj06974"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_PuJY_809rM"
      },
      "source": [
        "#Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEsATiuR1Dm1"
      },
      "source": [
        "1. Please rename your notebook as *Assignment_1_aa1234.ipynb* before the final submission. Notebooks which do not follow appropriate naming convention will not be graded.\n",
        "\n",
        "2. Please submit your own work. If you have any questions, please feel free to reach out to the course instructors or RA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccbn_f1tuO5"
      },
      "source": [
        "# Assignment Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wzVkeRPuFeE"
      },
      "source": [
        "In this assignment, you are required to fine tune a LLM model of your that classifies which human value category a textual arguement belongs to. Your model will evaluated against 1-baseline, random-baseline results on the following dataset: test, Nahjalbalagha, Zhihu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaTUH4roAbNK"
      },
      "source": [
        "# Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pUce6g7dikYE"
      },
      "outputs": [],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQpDqfqAeLf"
      },
      "source": [
        "# Download Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIQHbYBWixhL"
      },
      "source": [
        "##Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNnoIZpRi4tG",
        "outputId": "67c2a793-ddd4-48d2-e9c2-e004f7a479ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-29 17:06:01--  https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/evaluator/evaluator.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 OK\n",
            "Length: 8708 (8.5K) [text/plain]\n",
            "Saving to: ‘evaluator.py.2’\n",
            "\n",
            "evaluator.py.2      100%[===================>]   8.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-29 17:06:02 (90.5 MB/s) - ‘evaluator.py.2’ saved [8708/8708]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/evaluator/evaluator.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1cuD7diLpQt"
      },
      "source": [
        "## 1-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qemjimf_F124",
        "outputId": "a0b95896-4da3-401b-a6d1-30d91a82b9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-29 17:06:02--  https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/1-baseline/1-baseline.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3613 (3.5K) [text/plain]\n",
            "Saving to: ‘1-baseline.py.2’\n",
            "\n",
            "1-baseline.py.2     100%[===================>]   3.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-29 17:06:02 (83.3 MB/s) - ‘1-baseline.py.2’ saved [3613/3613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/1-baseline/1-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpz1rfDxLsSd"
      },
      "source": [
        "## Random-Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1T_HfBIL6cM",
        "outputId": "d1e699f9-0d23-4946-86ce-93d2f6235edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-29 17:06:02--  https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/random-baseline/random-baseline.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5442 (5.3K) [text/plain]\n",
            "Saving to: ‘random-baseline.py.2’\n",
            "\n",
            "random-baseline.py. 100%[===================>]   5.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-29 17:06:03 (30.9 MB/s) - ‘random-baseline.py.2’ saved [5442/5442]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://raw.githubusercontent.com/touche-webis-de/touche-code/main/semeval23/human-value-detection/random-baseline/random-baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hP4MSUBLw6d"
      },
      "source": [
        "## Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbW6yi3-kzLV",
        "outputId": "3037cedb-d93a-454b-82dd-8b24e4ed5c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-29 17:06:03--  https://zenodo.org/api/records/10564870/files-archive\n",
            "Resolving zenodo.org (zenodo.org)... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188.185.79.172, 188.184.98.238, 188.184.103.159, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.79.172|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘files-archive.2’\n",
            "\n",
            "files-archive.2         [  <=>               ]   7.25M   591KB/s               ^C\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!wget https://zenodo.org/api/records/10564870/files-archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqWSKoZYg889",
        "outputId": "3a21c33b-e833-44d4-a287-399bbe0ed77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  files-archive\n",
            " extracting: Dataset/value-categories.json  \n",
            " extracting: Dataset/arguments-validation-zhihu.tsv  \n",
            " extracting: Dataset/level1-labels-training.tsv  \n",
            " extracting: Dataset/arguments-test-nahjalbalagha.tsv  \n",
            " extracting: Dataset/arguments-test.tsv  \n",
            " extracting: Dataset/arguments-training.tsv  \n",
            " extracting: Dataset/arguments-validation.tsv  \n",
            " extracting: Dataset/labels-test-nahjalbalagha.tsv  \n",
            " extracting: Dataset/labels-test-nyt.tsv  \n",
            " extracting: Dataset/labels-test.tsv  \n",
            " extracting: Dataset/labels-training.tsv  \n",
            " extracting: Dataset/level1-labels-test-nahjalbalagha.tsv  \n",
            " extracting: Dataset/level1-labels-test.tsv  \n",
            " extracting: Dataset/level1-labels-test-nyt.tsv  \n",
            " extracting: Dataset/labels-validation.tsv  \n",
            " extracting: Dataset/labels-validation-zhihu.tsv  \n",
            " extracting: Dataset/meta-arguments-g.tsv  \n",
            " extracting: Dataset/meta-arguments-c.tsv  \n",
            " extracting: Dataset/meta-arguments-e.tsv  \n",
            " extracting: Dataset/meta-arguments-f.tsv  \n",
            " extracting: Dataset/level1-labels-validation.tsv  \n",
            " extracting: Dataset/level1-labels-validation-zhihu.tsv  \n",
            " extracting: Dataset/meta-arguments-a.tsv  \n",
            " extracting: Dataset/meta-arguments-d.tsv  \n",
            " extracting: Dataset/annotations-level1.tsv  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " extracting: Dataset/README.md       \n",
            " extracting: Dataset/comments-level1.tsv  \n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!unzip files-archive -d Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slE4sixQO3g3"
      },
      "outputs": [],
      "source": [
        "!mkdir Dataset/zhihu\n",
        "!mkdir Dataset/nahjalbalagha\n",
        "!mkdir Dataset/train\n",
        "!mkdir Dataset/test\n",
        "!mkdir Dataset/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6j3XShbOUcK",
        "outputId": "2e868218-3b04-476a-ff2c-8d461dc1f5ea"
      },
      "outputs": [],
      "source": [
        "!mv Dataset/*-zhihu.tsv Dataset/zhihu\n",
        "!mv Dataset/*-nahjalbalagha.tsv Dataset/nahjalbalagha\n",
        "!mv Dataset/*-training.tsv Dataset/train\n",
        "!mv Dataset/*-test.tsv Dataset/test\n",
        "!mv Dataset/*-validation.tsv Dataset/validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqfQxpk1rr3c"
      },
      "source": [
        "# Background Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VOGICHSEnPe"
      },
      "source": [
        "## Human Value Detection 2023 <br/>\n",
        "## SemEval 2023 Task 4. ValueEval: Identification of Human Values behind Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoK8u0VosGhF"
      },
      "source": [
        "\n",
        "\n",
        "Given a textual argument and a human value category, classify whether or not the argument draws on that category. This task uses a set of 20 value categories compiled from the social science literature and described in our [ACL paper](https://webis.de/publications.html#kiesel_2022b). Arguments are given as premise text, conclusion text, and binary stance of the premise to the conclusion (\"in favor of\" or \"against\").\n",
        "\n",
        "The 20 value categories are shown here on Schwartz' value continuum below:\n",
        "\n",
        "[![JEPBxUu.md.png](https://iili.io/JEPBxUu.md.png)](https://freeimage.host/i/JEPBxUu)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmfwBXIEqLN"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV37SsQqET4P"
      },
      "source": [
        "\n",
        "Data is provided as tab-separated values files with one header line. The arguments-validation.tsv files contain one argument per line: its unique argument ID, the conclusion, the premise's stance towards the conclusion, and the premise itself. Example with tab-separated columns are shown below\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Conclusion</span>\t<span class=\"column\">Stance</span>\t<span class=\"column\">Premise</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">We should prohibit school prayer</span>\t<span class=\"column\">against</span>\t<span class=\"column\">it should be allowed if the student wants to pray as long as it is not interfering with his classes</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">We should abolish the three-strikes laws</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">three strike laws can cause young people to be put away for life without a chance to straight out their life</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">The use of public defenders should be mandatory</span>\t<span class=\"column\">in favor of</span>\t<span class=\"column\">the use of public defenders should be mandatory because some people don't have money for a lawyer and this would help those that don't</span>\n",
        "</pre>\n",
        "\n",
        "The labels-validation.tsv  files also contain one argument per line: its unique argument ID and one column for each of the 20 value categories with a 1 meaning that the argument resorts to the value category and a 0 that not. Example with tab-separated columns are shown below:\n",
        "\n",
        "<pre><span class=\"column\">Argument ID</span>\t<span class=\"column\">Self-direction: thought</span>\t<span class=\"column\">Self-direction: action</span>\t<span class=\"column\">Stimulation</span>\t<span class=\"column\">Hedonism</span>\t<span class=\"column\">Achievement</span>\t<span class=\"column\">Power: dominance</span>\t<span class=\"column\">Power: resources</span>\t<span class=\"column\">Face</span>\t<span class=\"column\">Security: personal</span>\t<span class=\"column\">Security: societal</span>\t<span class=\"column\">Tradition</span>\t<span class=\"column\">Conformity: rules</span>\t<span class=\"column\">Conformity: interpersonal</span>\t<span class=\"column\">Humility</span>\t<span class=\"column\">Benevolence: caring</span>\t<span class=\"column\">Benevolence: dependability</span>\t<span class=\"column\">Universalism: concern</span>\t<span class=\"column\">Universalism: nature</span>\t<span class=\"column\">Universalism: tolerance</span>\t<span class=\"column\">Universalism: objectivity</span>\n",
        "<span class=\"column\">A01010</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "<span class=\"column\">A01011</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">1</span>\n",
        "<span class=\"column\">A01012</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">1</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\t<span class=\"column\">0</span>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCUwSn5ET4R"
      },
      "source": [
        "In addition, there are other datasets for evaluating the robustness of our model: validation-zhihu from the recommendation and hotlist section of the Chinese question-answering website Zhihu, test-nahjalbalagha from and based on the Nahj al-Balagha.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTbj-CWGET4S"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0aIoUoET4T"
      },
      "source": [
        "Runs are evaluated on the basis of F1-score, Precision, and Recall: averaged over all value categories and for each category individually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPq0nLudMRr6"
      },
      "source": [
        "## Baseline Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3bNgmUjmBm7"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT\n",
        "# RUN ONLY ONCE\n",
        "!mkdir baseline\n",
        "!mkdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiNl_AFGMlKm"
      },
      "source": [
        "### 1-Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aAGZXIoxSk"
      },
      "source": [
        "#### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs9M_yVXkCci",
        "outputId": "c2824bb1-896c-4b01-9fe1-4f1bb9d2dc34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/1-baseline.py': [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/mj06974/IntroToLLM/Assignment 1/evaluator.py\", line 152, in <module>\n",
            "    writeEvaluation(readLabels(args.inputDataset, prefix=\"labels-\"), readLabels(args.inputRun), args.outputDataset)\n",
            "  File \"/home/mj06974/IntroToLLM/Assignment 1/evaluator.py\", line 30, in readLabels\n",
            "    for labelsBaseName in os.listdir(directory):\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/Dataset/test/'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "head: cannot open '/content/output/evaluation.prototext' for reading: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/test --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/test/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZimLuvQro0Un"
      },
      "source": [
        "#### Zhihu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdj9s6UapKNI",
        "outputId": "624c269f-0417-4cf7-8d2d-c6b73e0d5530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading /content/Dataset/zhihu/arguments-validation-zhihu.tsv\n",
            "Labeling 100 instances\n",
            "Detected values: {'Security: personal', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Conformity: interpersonal', 'Conformity: rules', 'Self-direction: thought', 'Face', 'Achievement', 'Security: societal', 'Humility', 'Power: resources', 'Tradition', 'Universalism: objectivity', 'Universalism: tolerance', 'Stimulation', 'Hedonism', 'Benevolence: caring', 'Self-direction: action', 'Power: dominance'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/zhihu/labels-validation-zhihu.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 100\n",
            "Run labels:   100\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.2292179045745204\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.12944444444444445\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"1.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/zhihu/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/zhihu/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM73FR4vo32i"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1fhW1vnpUe3",
        "outputId": "cc36d664-44f0-4965-d943-c62d77cc00e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading /content/Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\n",
            "Labeling 279 instances\n",
            "Detected values: {'Self-direction: action', 'Security: personal', 'Security: societal', 'Tradition', 'Achievement', 'Power: resources', 'Universalism: tolerance', 'Hedonism', 'Universalism: nature', 'Self-direction: thought', 'Conformity: interpersonal', 'Universalism: concern', 'Conformity: rules', 'Universalism: objectivity', 'Humility', 'Power: dominance', 'Stimulation', 'Benevolence: dependability', 'Benevolence: caring', 'Face'}\n",
            "Writing run file\n",
            "Reading /content/Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\n",
            "Reading /content/baseline/run.tsv\n",
            "Truth labels: 279\n",
            "Run labels:   279\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.12845882944826426\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.0686379928315412\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"1.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 /content/1-baseline.py --inputDataset /content/Dataset/nahjalbalagha/ --outputDataset /content/baseline\n",
        "!python3 evaluator.py --inputDataset /content/Dataset/nahjalbalagha/ --inputRun /content/baseline --outputDataset /content/output\n",
        "!head -n 12 /content/output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCKuzb-RMp6u"
      },
      "source": [
        "### Random-Baseline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k07k6xKvpAPO"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-SbkcWxr0Sv",
        "outputId": "92d414d2-b2ac-4250-b21a-100f967fd910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Dataset/test/arguments-test.tsv\n",
            "Labeling 1576 instances\n",
            "Detected values: {'Humility', 'Face', 'Tradition', 'Stimulation', 'Security: societal', 'Power: resources', 'Benevolence: dependability', 'Universalism: tolerance', 'Self-direction: action', 'Power: dominance', 'Universalism: concern', 'Conformity: rules', 'Benevolence: caring', 'Universalism: objectivity', 'Hedonism', 'Universalism: nature', 'Achievement', 'Self-direction: thought', 'Security: personal', 'Conformity: interpersonal'}\n",
            "Writing run file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Dataset/test/labels-test.tsv\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/mj06974/IntroToLLM/Assignment 1/evaluator.py\", line 152, in <module>\n",
            "    writeEvaluation(readLabels(args.inputDataset, prefix=\"labels-\"), readLabels(args.inputRun), args.outputDataset)\n",
            "  File \"/home/mj06974/IntroToLLM/Assignment 1/evaluator.py\", line 69, in readLabels\n",
            "    raise OSError(\"No labels found in directory '\" + directory + \"'\")\n",
            "OSError: No labels found in directory 'baseline1'\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.1619145366405842\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.15076157559181208\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.17484945850262804\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/test --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/test/ --inputRun baseline1 --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDhh7of4pCAS"
      },
      "source": [
        "#### Zhihu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN6mZ5jOr2Zp",
        "outputId": "4d95a320-54ef-4f04-9446-10983523ce37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Dataset/zhihu/arguments-validation-zhihu.tsv\n",
            "Labeling 100 instances\n",
            "Detected values: {'Face', 'Self-direction: action', 'Power: resources', 'Achievement', 'Power: dominance', 'Universalism: objectivity', 'Conformity: interpersonal', 'Self-direction: thought', 'Conformity: rules', 'Benevolence: dependability', 'Benevolence: caring', 'Universalism: nature', 'Tradition', 'Universalism: tolerance', 'Humility', 'Security: personal', 'Security: societal', 'Universalism: concern', 'Hedonism', 'Stimulation'}\n",
            "Writing run file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Dataset/zhihu/labels-validation-zhihu.tsv\n",
            "Reading baseline/run.tsv\n",
            "Truth labels: 100\n",
            "Run labels:   100\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.18565993486656684\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.15400517885128007\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.23369425958560086\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/zhihu/ --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/zhihu/ --inputRun baseline --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gg-ZIzQpEn3"
      },
      "source": [
        "#### Nahjalbalagha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WurMCZZSsBIU",
        "outputId": "38e80f94-68d2-40f0-8b6a-f104306c1a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\n",
            "Labeling 279 instances\n",
            "Detected values: {'Achievement', 'Stimulation', 'Security: personal', 'Power: resources', 'Security: societal', 'Conformity: interpersonal', 'Hedonism', 'Universalism: objectivity', 'Benevolence: caring', 'Conformity: rules', 'Benevolence: dependability', 'Power: dominance', 'Humility', 'Self-direction: thought', 'Tradition', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: concern', 'Face', 'Self-direction: action'}\n",
            "Writing run file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\n",
            "Reading baseline/run.tsv\n",
            "Truth labels: 279\n",
            "Run labels:   279\n",
            "measure {\n",
            " key: \"F1\"\n",
            " value: \"0.08931047097840349\"\n",
            "}\n",
            "measure {\n",
            " key: \"Precision\"\n",
            " value: \"0.06366324442396012\"\n",
            "}\n",
            "measure {\n",
            " key: \"Recall\"\n",
            " value: \"0.14956312265615454\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT\n",
        "!python3 random-baseline.py --inputDataset Dataset/nahjalbalagha/ --outputDataset baseline\n",
        "!python3 evaluator.py --inputDataset Dataset/nahjalbalagha/ --inputRun baseline --outputDataset output\n",
        "!head -n 12 output/evaluation.prototext\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aub8gmh_xfOz"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvwbxxhcwIwo"
      },
      "source": [
        "## [20 Points] Task 01 - Load Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ6f0D1zwj9P"
      },
      "source": [
        "In this task, you are required to load the Training, Test, Validation, Nahjalbalagha & Zhihu into seperate dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORT ALL YOUR LIBRARIES\n",
        "# SUGGESTED LIBRARIES\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification,BertModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import cuda\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hicJHRw0piGN"
      },
      "outputs": [],
      "source": [
        "# Importing files into dataframes:  naming convention: \n",
        "# dataset_arguments = the data\n",
        "# dataset_result_sem_eval = the answers to the data\n",
        "# dataset_result_level_1 = don't know what that is right now, maybe some answers for some other task. \n",
        "\n",
        "# Nahjalbalagah\n",
        "nahjalbalagha_arguments = pd.read_csv(\"Dataset/nahjalbalagha/arguments-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "nahjalbalagha_result_sem_eval= pd.read_csv(\"Dataset/nahjalbalagha/labels-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "nahjalbalagha_result_level_1= pd.read_csv(\"Dataset/nahjalbalagha/level1-labels-test-nahjalbalagha.tsv\",sep=\"\\t\")\n",
        "# Zhihu \n",
        "zhihu_arguments = pd.read_csv(\"Dataset/zhihu/arguments-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "zhihu_result_sem_eval = pd.read_csv(\"Dataset/zhihu/labels-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "zhihu_result_level_1 = pd.read_csv(\"Dataset/zhihu/level1-labels-validation-zhihu.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Testing \n",
        "test_arguments = pd.read_csv(\"Dataset/test/arguments-test.tsv\",sep=\"\\t\")\n",
        "test_result_sem_eval = pd.read_csv(\"Dataset/test/labels-test.tsv\",sep=\"\\t\")\n",
        "test_result_level_1 = pd.read_csv(\"Dataset/test/level1-labels-test.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Training Dataset\n",
        "training_arguments = pd.read_csv(\"Dataset/train/arguments-training.tsv\",sep=\"\\t\")\n",
        "training_result_sem_eval = pd.read_csv(\"Dataset/train/labels-training.tsv\",sep=\"\\t\")\n",
        "training_result_level_1 = pd.read_csv(\"Dataset/train/level1-labels-training.tsv\",sep=\"\\t\")\n",
        "\n",
        "# Validation \n",
        "validation_arguments = pd.read_csv(\"Dataset/validation/arguments-validation.tsv\",sep=\"\\t\")\n",
        "validation_result_sem_eval = pd.read_csv(\"Dataset/validation/labels-validation.tsv\",sep=\"\\t\")\n",
        "validation_result_level_1 = pd.read_csv(\"Dataset/validation/level1-labels-validation.tsv\",sep=\"\\t\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Merging Dataframes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "label_dict={\n",
        "    0: \"\",\n",
        "    1: \"Self-direction: thought\",\n",
        "    2: \"Self-direction: action\",\n",
        "    3: \"Stimulation\",\n",
        "    4: \"Hedonism\",\n",
        "    5: \"Achievement\",\n",
        "    6: \"Power: dominance\",\n",
        "    7: \"Power: resources\",\n",
        "    8: \"Face\",\n",
        "    9: \"Security: personal\",\n",
        "    10: \"Security: societal\",\n",
        "    11: \"Tradition\",\n",
        "    12: \"Conformity: rules\",\n",
        "    13: \"Conformity: interpersonal\",\n",
        "    14: \"Humility\",\n",
        "    15: \"Benevolence: caring\",\n",
        "    16: \"Benevolence: dependability\",\n",
        "    17: \"Universalism: concern\",\n",
        "    18: \"Universalism: nature\",\n",
        "    19: \"Universalism: tolerance\",\n",
        "    20: \"Universalism: objectivity\"\n",
        "}\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "argument_values = {}\n",
        "\n",
        "# Iterate over each row in the dataframe\n",
        "for index, row in training_result_sem_eval.iterrows():\n",
        "    # Get the 'Argument ID'\n",
        "    argument_id = row['Argument ID']\n",
        "    # Initialize an empty list to store column names with value 1\n",
        "    columns_with_1 = []\n",
        "    # Iterate over each column in the row (starting from index 1 to skip 'Argument ID')\n",
        "    for col in training_result_sem_eval.columns[1:]:\n",
        "        # Check if the value in the current column is 1\n",
        "        if row[col] == 1:\n",
        "            # If so, append the column name to the list\n",
        "            columns_with_1.append(label_dict_inverse[col])\n",
        "    # Add the 'Argument ID' and list of columns with value 1 to the dictionary\n",
        "    argument_values[argument_id] = columns_with_1\n",
        "df_argument_values = pd.DataFrame(argument_values.items(), columns=['Argument ID', 'category'])\n",
        "\n",
        "merged_df = pd.merge(training_arguments, df_argument_values, on='Argument ID', how='left')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [10 Points] Task 02 - Define Tokenizer & Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-GrMJPcx3W3"
      },
      "source": [
        "In this task, you are required to define the Tokenizer and LLM model of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iNVCZzye2Mz4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 1037, 24096, 8889, 2475, 1010, 2057, 2323, 7221, 2529, 18856, 13369, 1010, 1999, 5684, 1997, 1010, 2057, 2323, 7221, 2529, 18856, 13369, 2004, 2009, 2097, 2069, 3426, 4121, 3314, 2043, 2017, 2031, 1037, 9129, 1997, 1996, 2168, 4286, 2770, 2105, 2035, 3772, 1996, 2168, 1012, 1010, 1031, 2184, 1033, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Write your code here\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',num_labels=20)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\",id2label=label_dict,label2id=label_dict_inverse)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "text_data = merged_df.apply(lambda row: ','.join(map(str, row)), axis=1).tolist()\n",
        "# print(type(text_data))\n",
        "data=[tokenizer(text,padding=True) for text in text_data]\n",
        "\n",
        "# print(data)\n",
        "# Reference # 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHVo6_LBBmS"
      },
      "source": [
        "## [20 Points] Task 03 - Optimizer & Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_U-toJPyWU2"
      },
      "source": [
        "In this task, you are required to define the hyperparameters & the optimizer for training your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IRCnPVc1y8C-"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "BATCH_SIZE = 32\n",
        "NUM_PROCS = 32\n",
        "LR = 0.00005\n",
        "EPOCHS = 5\n",
        "MODEL = 'bert-base-uncased'\n",
        "OUT_DIR = 'finetuned '+ MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0hSUmrBBGI4"
      },
      "source": [
        "## [20 Points] Task 04 -  Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIT5b7E6yuC3"
      },
      "source": [
        "In this task, you are required to implement the training loop for fine tuning your model. You are also required to plot on the same graph: Loss vs Epochs & Accuracy vs Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Egtj2TzwzVrp"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-NOEm2ezYUt"
      },
      "source": [
        "## [10 Points]  Task 05 - Model Evaluation: Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kjnR9qzuZG"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Test dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AkJAygxszgj7"
      },
      "outputs": [],
      "source": [
        "#Write your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU4HaMYnzhJv"
      },
      "source": [
        "## [10 Points]  Task 06 - Model Evaluation: Zhihu Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT5t6TbG0F_O"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Zhihu\n",
        " dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVP0kNHOzixT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4ZsjvNzj0-"
      },
      "source": [
        "## [10 Points]  Task 07 - Model Evaluation: Nahjalbalagha Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KkhxR3p0KAF"
      },
      "source": [
        "In this task, you are required your fine tuned model on the Nahjalbalagha dataset using ``evaluator.py`` and compare your results with random and 1-baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQnoTEUzlJU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I0v4IKS0OA9"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6B-tga80RDu"
      },
      "source": [
        "In this section, cite any resources or references that you use for solving this assignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "title = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding}\n",
        "Link : https://huggingface.co/google-bert/bert-base-uncased \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
